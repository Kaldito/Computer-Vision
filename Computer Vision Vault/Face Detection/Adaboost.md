AdaBoost, que significa "Adaptive Boosting", es un algoritmo de machine learning utilizado para mejorar la precisión de los sistemas de clasificación. Es un método de ensemble, lo que significa que combina múltiples clasificadores débiles para crear un clasificador fuerte y más preciso. Un clasificador débil es simplemente un modelo que funciona ligeramente mejor que el azar. AdaBoost ayuda a ajustar estos clasificadores débiles de manera que puedan corregir sus errores previos y mejorar su capacidad de predicción.

La idea básica detrás de AdaBoost es asignar pesos a cada instancia de entrenamiento y ajustar estos pesos después de cada clasificación. Inicialmente, todos los datos de entrenamiento tienen el mismo peso. Sin embargo, después de cada ronda de clasificación, AdaBoost aumenta los pesos de las instancias mal clasificadas y disminuye los pesos de las instancias bien clasificadas. Esto significa que en la siguiente ronda, el clasificador se enfocará más en los casos que fueron difíciles de clasificar previamente, intentando corregir esos errores.